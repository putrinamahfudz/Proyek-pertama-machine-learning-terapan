# -*- coding: utf-8 -*-
"""ProyekPertamaMLT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16_Ma587dinWGzYbOuhkUeIOkE3l2iulC

## **PUTRI NUR AINI MAHFUDZ (M203Y0411)**

## **Proyek Pertama Kelas Machine Learning Terapan**

---

### Impor library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

from sklearn.utils import resample
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, r2_score, confusion_matrix

"""## **Data Understanding**

Penjelasan mengenai variabel yang ada pada dataset adalah sebagai berikut:
- id: merupakan parameter yang bernilai unik yang dimiliki setiap subjek.
- gender: merupakan fitur yang menyatakan jenis kelamin.
- age: merupakan fitur yang menyatakan usia.
- hypertension: merupakan fitur yang menyatakan apakah mengidap hipertensi. 0: tidak, 1: ya.
- heart_disease: merupakan fitur yang menyatakan apakah mengidap penyakit jantung. 0: tidak, 1: ya.
- ever_married: merupakan fitur yang menyatakan apakah sudah pernah menikah. 
- work_type: merupakan fitur yang menyatakan jenis pekerjaan.
- Residence_type: merupakan fitur yang menyatakan jenis tempat tinggal.
- avg_glucose_level: merupakan fitur yang menyatakan kadar gula darah rata-rata.
- bmi: merupakan fitur yang menyatakan kategori berat badan.
- smoking_status: merupakan fitur yang menyatakan kategori merokok.
- stroke: merupakan fitur target yang menyatakan apakah terdiagnosis stroke. 0: tidak, 1: ya.

### Ubah dataset menjadi dataframe, lalu tampilkan isi dataset
"""

df = pd.read_csv('stroke_data.csv')
df

"""### Melihat jumlah row dan column"""

df.shape

"""### Melihat informasi kolom pada dataset"""

df.info()

"""### Melihat hitungan rata-rata, dll pada dataset"""

df.describe()

"""### Melihat jumlah data kosong pada setiap kolom"""

df.isna().sum()

"""### Mengecek apakah ada data yang terduplikat"""

duplicates = df[df.duplicated()]
len(duplicates)

"""### Mengecek apakah data sudah seimbang atau belum"""

df.stroke.value_counts()

"""## Visualisasi Data

### Visualisasi Univariate Analysis

Tahapan ini dilakukan untuk melihat distribusi data setiap variabel
"""

df['gender'].value_counts().plot(kind='bar')

"""Gambar 1. Distribusi gender


> Pada Gambar 1, terdapat perbandingan value antara tiga kategori yang menyatakan jenis kelamin (female, male, dan other)


"""

df['ever_married'].value_counts().plot(kind='bar')

"""Gambar 2. Distribusi ever_married


> Pada Gambar 2, terdapat perbandingan value antara dua kategori yang menyatakan apakah sudah pernah menikah (yes dan no)
"""

df['work_type'].value_counts().plot(kind='bar')

"""Gambar 3. Distribusi work_type

> Pada Gambar 3, terdapat perbandingan value antara lima kategori yang menyatakan jenis pekerjaan (private, self_employed, children, govt_job, never_worked)
"""

df['Residence_type'].value_counts().plot(kind='bar')

"""Gambar 4. Distribusi Residence_type

> Pada Gambar 4, terdapat perbandingan value antara dua kategori yang menyatakan jenis tempat tinggal (urban dan rural)
"""

df.hist(figsize=(16,12))
plt.show()

"""Gambar 5. Distribusi dari id, age, hypertension, heart_disease, avg_glucose_level, bmi, stroke

> Pada Gambar 5, terdapat perbandingan value di fitur-fitur yang tertera

## **Data Preparation**

## Menghapus kolom yang tidak diperlukan

Kolom atau variabel yang dihapus adalah id, karena tidak memiliki kepentingan untuk dimasukkan ke dalam model
"""

df.drop(['id'], axis=1, inplace=True)
df.head()

"""## Menghapus kategori pada kolom yang tidak diperlukan

Kategori yang dihapus adalah unknown pada kolom smoking_status dan other pada kolom gender
"""

categorical = list(df.dtypes[df.dtypes == 'object'].index)
categorical
for col in categorical:
    df[col] = df[col].str.lower().str.replace(" ", "_")

for col in categorical:
    print(col)
    print(df[col].unique())

df.drop(df.loc[df['smoking_status']=='unknown'].index, inplace=True)

df.drop(df.loc[df['gender']=='other'].index, inplace=True)

df.reset_index(drop=True)

"""## Penanganan data yang hilang dengan nilai rata-rata

Dalam dataset ini, ada sebanyak 201 data kosong pada kolom bmi. maka diterapkan teknik melakukan imputasi atau nilai pengganti. nilai pengganti yang digunakan adalah nilai rata-rata (mean)
"""

df['bmi'].fillna(df['bmi'].mean(), inplace = True)
display(df.isnull().sum().to_frame().reset_index().rename({'index' : 'Variables', 0: 'Missing Values'}, axis =1).style.background_gradient('gnuplot2_r'))

"""## Melakukan upsample agar data seimbang

Dilakukan upsample agar data menjadi seimbang dan menghasilkan prediksi yang bagus
"""

df_1 = df[df.stroke==0]
df_2 = df[df.stroke==1]
df_2_upsampled = resample(df_2,
                          replace=True,
                          n_samples=3364,
                          random_state=123) 
df_upsampled = pd.concat([df_1, df_2_upsampled])
df_upsampled.stroke.value_counts()

df_upsampled.reset_index(drop=True)

stroke_label = df_upsampled.stroke.value_counts()
plt.figure(figsize=(8, 4))
sns.barplot(stroke_label.index, stroke_label);
plt.xlabel('Stroke', fontsize=15);
plt.ylabel('Jumlah', fontsize=15)

"""## Melihat visualisasi distribusi kolom numerikal setelah diupsample"""

numerical = [col for col in df_upsampled.columns if col not in categorical]

for i in numerical:
    ax = sns.distplot(df_upsampled[i], color = 'red')
    plt.title('%s' %i, fontsize = 15)
    plt.xlabel(' ')
    plt.ylabel(' ')
    plt.xticks(fontsize = 8)
    plt.show();
    print('\n')

"""## Melihat distribusi kolom kategorikal setelah diupsample"""

def sort_order(column):
    orders = (df_upsampled.groupby([column]).mean().sort_values(by ='stroke', ascending = False)).index
    return orders

for i in categorical:
    if df_upsampled[i].nunique() < 20:
        f,ax=plt.subplots(figsize=(7,7))
        sns.barplot(df_upsampled[i],df_upsampled['stroke'], order = sort_order(i), palette='Pastel1')
        plt.xlabel('%s'%i)
        plt.ylabel('stroke')
        plt.xticks(fontsize = 15, rotation = 90)
        plt.show();
        print('\n')

"""### Korelasi makriks setelah dilakukan upsample"""

plt.figure(figsize=(12, 10))
correlation_matrix = df_upsampled.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='bwr')
plt.title('Correlation Matrix', size=15)

df_upsampled.corr()['stroke'].sort_values(ascending=False)[1:]

"""## Mendeteksi Outliers"""

def outlier(data1):
    sorted(data1)
    Q1,Q3 = np.nanpercentile(data1, [25,75])
    IQR = Q3 - Q1
    lowerRange = Q1 - (1.5 * IQR)
    upperRange = Q3 + (1.5 * IQR)

    return lowerRange,upperRange

df_upsampled.value_counts('stroke')

"""### Melihat visualisasi distribusi fitur sebelum outliers dihapus"""

plt.figure(figsize=(20,10))

plt.subplot(2,4,1)
sns.distplot(df_upsampled['age'])
plt.xlabel('Age',fontsize = 12)
plt.grid()

plt.subplot(2,4,2)
sns.distplot(df_upsampled['avg_glucose_level'])
plt.xlabel('Avg Glucose Level',fontsize = 12)
plt.grid()

plt.subplot(2,4,3)
sns.distplot(df_upsampled['bmi'])
plt.xlabel('BMI',fontsize = 12)
plt.grid()

plt.show()

def graph(y):
    sns.boxplot(x="stroke", y=y, data=df_upsampled)
  
plt.figure(figsize=(14,7))
      
plt.subplot(2,4,1)
graph('age')
  
plt.subplot(2,4,2)
graph('avg_glucose_level')
  
plt.subplot(2,4,3)
graph('bmi')
  
plt.show()

lr,ur=outlier(df_upsampled['avg_glucose_level'][df_upsampled.stroke==0])
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level > ur) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level < lr) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.value_counts('stroke')

lr,ur=outlier(df_upsampled['avg_glucose_level'][df_upsampled.stroke==0])
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level > ur) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level < lr) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.value_counts('stroke')

lr,ur=outlier(df_upsampled['bmi'][df_upsampled.stroke==1])
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi > ur) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi < lr) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.value_counts('stroke')

lr,ur=outlier(df_upsampled['bmi'][df_upsampled.stroke==1])
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi > ur) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi < lr) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.value_counts('stroke')

def graph(y):
    sns.boxplot(x="stroke", y=y, data=df_upsampled)
  
plt.figure(figsize=(14,7))
      
plt.subplot(2,4,1)
graph('age')
  
plt.subplot(2,4,2)
graph('avg_glucose_level')
  
plt.subplot(2,4,3)
graph('bmi')
  
plt.show()

lr,ur=outlier(df_upsampled['bmi'][df_upsampled.stroke==1])
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi > ur) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi < lr) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.value_counts('stroke')

lr,ur=outlier(df_upsampled['avg_glucose_level'][df_upsampled.stroke==0])
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level > ur) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level < lr) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.value_counts('stroke')

def graph(y):
    sns.boxplot(x="stroke", y=y, data=df_upsampled)
  
plt.figure(figsize=(14,7))
      
plt.subplot(2,4,1)
graph('age')
  
plt.subplot(2,4,2)
graph('avg_glucose_level')
  
plt.subplot(2,4,3)
graph('bmi')
  
plt.show()

lr,ur=outlier(df_upsampled['avg_glucose_level'][df_upsampled.stroke==0])
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level > ur) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.avg_glucose_level < lr) & (df_upsampled.stroke == 0)],inplace=True)
df_upsampled.value_counts('stroke')

lr,ur=outlier(df_upsampled['bmi'][df_upsampled.stroke==1])
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi > ur) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.drop(df_upsampled.index[(df_upsampled.bmi < lr) & (df_upsampled.stroke == 1)],inplace=True)
df_upsampled.value_counts('stroke')

def graph(y):
    sns.boxplot(x="stroke", y=y, data=df_upsampled)
  
plt.figure(figsize=(14,7))
      
plt.subplot(2,4,1)
graph('age')
  
plt.subplot(2,4,2)
graph('avg_glucose_level')
  
plt.subplot(2,4,3)
graph('bmi')

"""### Melihat visualisasi distribusi fitur setelah outliers dihapus"""

plt.figure(figsize=(20,10))

plt.subplot(2,4,1)
sns.distplot(df_upsampled['age'])
plt.xlabel('Age',fontsize = 12)
plt.grid()

plt.subplot(2,4,2)
sns.distplot(df_upsampled['avg_glucose_level'])
plt.xlabel('Average Glucose Level',fontsize = 12)
plt.grid()

plt.subplot(2,4,3)
sns.distplot(df_upsampled['bmi'])
plt.xlabel('BMI',fontsize = 12)
plt.grid()

plt.show()

df_upsampled.reset_index(drop=True,inplace=True)

"""### One Hot Encoding

Teknik dilakukan pada data kategorikal agar datanya berubah menjadi data numerikal
"""

final=pd.get_dummies(df_upsampled, columns=['gender','ever_married','work_type','Residence_type','smoking_status'])
final.head()

"""### Melihat matriks korelasi setelah dilakukan encoding"""

plt.figure(figsize=(12,10))
sns.heatmap(final.corr(), annot=True, cmap='bwr');
plt.title('Correlation Matrix', fontsize=15);

"""### Melihat fitur apa saja yang memiliki peran penting

Teknik ini dilakukan untuk melihat fitur apa saja yang memiliki peranan penting untuk membuat model
"""

final.corr()['stroke'].sort_values(ascending=False)[1:]

feature_final=final[['age','hypertension','heart_disease','avg_glucose_level','bmi','gender_female','gender_male','ever_married_no','ever_married_yes','work_type_children','work_type_govt_job','work_type_never_worked','work_type_private','work_type_self-employed','Residence_type_rural','Residence_type_urban','smoking_status_formerly_smoked','smoking_status_never_smoked','smoking_status_smokes']]
target=final[['stroke']]

"""Digunakan RandomForestClassifier untuk mengecek"""

rf = RandomForestClassifier()
rf_model=rf.fit(feature_final,target)
feat_importances = pd.Series(rf_model.feature_importances_, index=feature_final.columns)
feat_importances.nlargest(12).plot(kind='barh')

"""Berdasarkan data di atas, dapat disimpulkan bahwa fitur Age, Average Glucose Level, dan BMI memiliki peranan yang sangat penting untuk digunakan dalam membuat model machine learning

### Membagi dataset, kemudian lakukan normalisasi
"""

final_features=final[['age', 'avg_glucose_level', 'bmi']]
target = final['stroke']

X_train, X_test, y_train, y_test = train_test_split(final_features,target,test_size = 0.2,random_state =2)
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## Modeling

### Menggunakan Random Forest Classifier

Dalam mengimplementasikan algoritma Random Forest, saya menggunakan method RandomForestClassifier dari sklearn.ensemble dengan argumen n_estimators=30 dan max_features=3. Kelebihan dari algoritma yang ini adalah dapat memperkiraan variabel apa yang penting dalam klasifikasi, sedangkan kekurangan dari algoritma ini yaitu memiliki kompleksitas yang tinggi.
"""

rf = RandomForestClassifier(n_estimators=30, max_features=3, random_state=0).fit(X_train_scaled, y_train)
rf_pred= rf.score(X_test_scaled, y_test)


rf_train_accuracy =rf.score(X_train_scaled,y_train)
rf_accuracy = rf.score(X_test_scaled,y_test)
pred_prob_rf = rf.predict_proba(X_test_scaled)


print("Training score: {}".format(rf.score(X_train_scaled, y_train)))
print("Test score: {}".format(rf.score(X_test_scaled, y_test)))

rf_model=RandomForestClassifier(random_state=0)
rf_model.fit(X_train_scaled,y_train)
y_pred=rf_model.predict(X_test_scaled)
from sklearn import metrics

rf_cm = metrics.confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(rf_cm, annot=True, fmt=".0f", linewidths=.5, square = True, cmap = 'bwr');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Confusion Matrix - score:'+str(metrics.accuracy_score(y_test,y_pred))
plt.title(all_sample_title, size = 15);
plt.show()
print(metrics.classification_report(y_test,y_pred))

"""### Menggunakan KNeighbors Classifier

Dalam mengimplementasikan algoritma KNN, saya menggunakan method KNeighborsClassifier dari sklearn.neighbors dengan argumen n_neighbors=2. Kelebihan dari algoritma yang ini adalah cukup efektif terhadap data yang besar, sedangkan kekurangan dari algoritma ini yaitu perlu menentukan nilai parameter K terlebih dahulu.
"""

knn = KNeighborsClassifier()
knn.fit(X_train_scaled, y_train)
knn_pred=knn.score(X_test_scaled, y_test)

knn_train_accuracy =knn.score(X_train_scaled,y_train)
knn_accuracy = knn.score(X_test_scaled,y_test)
pred_prob_knn = knn.predict_proba(X_test_scaled)

print("Training score: {}".format(knn.score(X_train_scaled, y_train)))
print("Test score: {}".format(knn.score(X_test_scaled, y_test)))

k_range = range(1,11)
scores = []

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors = k)
    knn.fit(X_train_scaled, y_train)
    scores.append(knn.score(X_test_scaled, y_test))

plt.xlabel('k')
plt.ylabel('accuracy')
plt.scatter(k_range, scores)
plt.vlines(k_range,0, scores, linestyle="dashed", colors='maroon')
plt.ylim(0.70,0.99)
plt.xticks([i for i in range(1,11)]);

knn_model=KNeighborsClassifier(n_neighbors = 2)
knn_model.fit(X_train_scaled,y_train)
y_pred=knn_model.predict(X_test_scaled)
from sklearn import metrics

knn_cm = metrics.confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(knn_cm, annot=True, fmt=".0f", linewidths=.5, square = True, cmap = 'bwr');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Confusion Matrix - score:'+str(metrics.accuracy_score(y_test,y_pred))
plt.title(all_sample_title, size = 15);
plt.show()
print(metrics.classification_report(y_test,y_pred))

"""## Evaluation

### Perbandingan Akurasi
"""

Model_Name = ['Random Forest','KNeighbors']
Accuracy = [rf_pred,knn_pred]

plt.bar
plt.title('Perbandingan akurasi model')
plt.xlabel('Akurasi')
plt.ylabel('Model')
sns.barplot(x = Accuracy,y = Model_Name)
plt.show()

"""Gambar 6. Perbandingan Akurasi


> Pada Gambar 6, dapat diketahui bahwa model dengan Random Forest memiliki akurasi yang lebih tinggi dibanding KNeighbors.

## **Terimakasih.**

## **Submission project kelas Machine Learning Terapan - 2022**
"""